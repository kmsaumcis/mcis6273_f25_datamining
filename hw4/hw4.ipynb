{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["\\begin{center}\n", "\\begin{huge}\n", "MCIS6273 Data Mining (Prof. Maull) / Fall 2025 / HW4\n", "\\end{huge}\n", "\\end{center}\n", "\n", "| Points <br/>Possible | Due Date | Time Commitment <br/>(estimated) |\n", "|:---------------:|:--------:|:---------------:|\n", "| 20 | Monday December 8 @ Midnight | _up to_ 20 hours |\n", "\n", "\n", "* **GRADING:** Grading will be aligned with the completeness of the objectives.\n", "\n", "* **INDEPENDENT WORK:** Copying, cheating, plagiarism  and academic dishonesty _are not tolerated_ by University or course policy.  Please see the syllabus for the full departmental and University statement on the academic code of honor.\n", "\n", "## OBJECTIVES\n", "* Perform data fusion with a new dataset.\n", "\n", "* Build a test and training dataset in preparation for a classifier.\n", "\n", "* Build a RandomForest classifier to learn the Aurora prediction label.\n", "\n", "* Complete the online assessment.\n", "\n", "## WHAT TO TURN IN\n", "You are being encouraged to turn the assignment in using the provided\n", "Jupyter Notebook.  To do so, make a directory in your Lab environment called\n", "`homework/hw4`.   Put all of your files in that directory.  Then zip or tar that directory,\n", "rename it with your name as the first part of the filename \n", "(e.g. `maull_hw4_files.zip`, `maull_hw4_files.tar.gz`), then\n", "download it to your local machine, then upload the `.zip` to Blackboard.\n", "\n", "If you do not know how to do this, please ask, or visit one of the \n", "many tutorials out there\n", "on the basics of using zip in Linux.\n", "\n", "If you choose not to use the provided notebook, you will still need to turn in a\n", "`.ipynb` Jupyter Notebook and corresponding files according to the instructions in\n", "this homework.\n", "\n", "\n", "## ASSIGNMENT TASKS\n", "### (25%) Perform data fusion with a new dataset. \n", "\n", "Now that we have developed some expertise in dark skies,\n", "we want to use what we know about supervised learning\n", "to make some predictions.\n", "\n", "In the last assignment, we learned about how to \n", "use imputation to fill in missing data.  This, for the most \n", "part, gave us a \"complete\" dataset, even if some \n", "of it was synthetic.  We must always weight the pros and cons \n", "of having a \"good enough\", but complete dataset or an incomplete\n", "dataset.\n", "\n", "This final assignment will challenge us further to make a prediction\n", "about where we might find the best possibilities for\n", "seeing the Aurora Borealis or the \"Northern Lights\".  If\n", "you are unfamiliar with\n", "this phenomenon, please take a look here:\n", "\n", "* [Northern lights (aurora borealis): What they are and how to see them?](https://www.space.com/15139-northern-lights-auroras-earth-facts-sdcmp.html) by Daisy Dobrijevic\n", "\n", "What we will ultimately land on is a binary classifier which\n", "might be able to tell us which locations would have been good places\n", "to see it (and possibly good places in the future).\n", "\n", "Some of the major features of such good places are:\n", "\n", "* latitude (usually in the northern hemisphere),\n", "* dark skies (usually > 21 bortle and without the moon),\n", "* intense solar activity -- without the appropriate minimum solar activity, \n", "  there will not be anything to see.\n", "\n", "You might notice, that we actually have two of these \n", "three features, but the third?  Solar acitity is a dataset \n", "we're going to have to obtain from external sources.\n", "\n", "So, in this first part we're going to begin to build the final\n", "data set which will allow us to train a classifier. \n", "\n", "In this part we will: \n", "\n", "* obtain the data,\n", "* assemble and merge a particular field back into our updated GaN dataset\n", "  which has complete (imputed) `SQMReadings` based on time-date\n", "information. \n", "\n", "\n", "One of the fun things about this is that we are going\n", "to learn how to merge external data with our original dataset\n", "and ultimately learn\n", "the process of  how to build a classifier based on that\n", "data. We will ultimately have a rudimentary classifier that allows us to\n", "know or to be, let's say, more aware of where in the \n", "world we would best see the\n", "Aurora Borealis by exploiting what we've already know about dark skies.\n", "\n", "**&#167; Task:**  **1.1 Load the _Matza, et al_ dataset into a DataFrame.**\n", "\n", "In this process  will have to learn a little bit more about \n", "the data that we are dealing with.  That data will come from\n", "the following repository:\n", "\n", "* [The GFZ Helmholtz Centre for Geosciences](https://www.gfz.de/en/) \n", "\n", "The dataset is:\n", "\n", "* Matzka, J., Stolle, C., Yamazaki, Y., Bronkalla, O. and Morschhauser, A., 2021. The geomagnetic Kp index and \n", "  derived indices of geomagnetic activity. \n", "  Space Weather, [https://doi.org/10.1029/2020SW002641](https://doi.org/10.1029/2020SW002641)\n", "\n", "Which can be downloaded directly from:\n", "\n", "* [https://kp.gfz.de/app/files/Kp_ap_Ap_SN_F107_since_1932.txt](https://kp.gfz.de/app/files/Kp_ap_Ap_SN_F107_since_1932.txt)\n", "\n", "\n", "\n", "You will need to set your `read_csv()` parameters \n", "appropriately:\n", "\n", "* set `sep=\"\\s+\"`,\n", "* skip the first 40 rows with `skiprows=`,\n", "* add back the columns (you must look at the original file\n", "  and on the 40th skipped line are the columns).\n", "\n", "\n", "**&#167; Task:**  **1.2 Remove all data prior to Jan 01, 2014 and save this data in a CSV file.**\n", "\n", "* You may want to merge the date fields into a datetime field -- \n", "  it will definitely make your life easier (e.g. convert YY MM DD into a \n", "  `datetime` object),\n", "* save the file into `data/014_2024_solar_activity.csv`.\n", "\n", "\n", "**&#167; Task:**  **1.3 Update your GaN dataset so it includes all original \n", "  and imputed `SQMReadings` as well as 4 new columns.**\n", "\n", "* you have already done the imputation in HW3, you just need to \n", "  go back to your prior work and integrate,\n", "* the new columns will be `\"season_winter\"`, \n", "`\"season_summer\"`, `\"season_fall\"`, `\"season_spring\"`\n", "which will be binary columns and be based on\n", "the month of the measurment.  You can easily \n", "do this with with the [`DataFrame.apply()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html) \n", "method by looking at the date and assigning a binary\n", "`1`  to the appropriate column and `0` everywhere else. \n", "For example, if the month for a GaN datapoint is March \n", "(3) `season_spring` will\n", "be assiged `1` and all other seasons `0`.\n", "\n", "Use the following as a guideline:\n", "\n", "* `season_spring` is any month in March (3),  April (4) or May (5),\n", "* `season_summer` is any month in June (6), July (7) or August (8),\n", "* `season_fall` is any month in September (9), October (10) or November (11),\n", "* `season_winter` is any month in December (12), January (1) or February (2). \n", "\n", "\n", "**&#167; Task:**  **1.4 Merge the `Ap` field from the _Matza, et al_ dataset\n", "into your GaN dataset.**\n", "\n", "This will require you to match the datetime of each\n", "dataset so that every row of the GaN data has \n", "a new field `\"Ap\"` which represents \n", "the `\"Ap\"` value for the date in the GaN row.\n", "\n", "\n", "**&#167; Task:**  **1.5 Read the short paper  which explains the \n", "`Ap` and `Kp` indices.**\n", "\n", "There is nothing to do here, except \n", "learn a little about the data we're using --\n", "as a data scientist, this is a necessary \n", "step to increase your awareness of the \n", "conxtext and domain.  This doesn't make \n", "you an instant expert, but rather a _trusted\n", "partner_ in data analysis.\n", "\n", "* [_Understanding Solar Indices_ by By Ian Poole, G3YWX](https://www.arrl.org/files/file/Technology/tis/info/pdf/0209038.pdf)\n", "\n", "\n", "\n", "### (25%) Build a test and training dataset in preparation for a classifier. \n", "\n", "\n", "In this second part, we're going to get our hands into building data\n", "sets for training and testing. \n", "\n", "Training datasets are necessary inputs\n", "to any supervised learning model and\n", "as we learned, they must have labeled \n", "data.  That is, there must be target \n", "labels included with the training\n", "data, else, there is nothing to learn from!\n", "\n", "\n", "We first must realize\n", "that the best way to build a data set\n", "is to work with a data set that we\n", "already have. And in this particular case there is \n", "good news -- we have a very good one with over\n", "100,000 rows worth of data that span a fairly long period of time from\n", "2014 to 2024. \n", "\n", "In order to build a good data set for the classifier, we're\n", "going to filter the new data set we have, \n", "set labels appropriately -- and in the case, yes, we're going\n", "to set them synthetically since we don't have the _actual_\n", "data label.  Finally,  we're\n", "going to split that labeled dataset into random sets\n", "of testing \n", "and training data. \n", "\n", "We need to remember that we are \n", "preparing to build a binary classifier (_positive_ class and\n", "_negative_ class), so in the training set we will need \n", "to have both positive and negative examples that are labeled.\n", "Within our dataset labeling data instances\n", "will be a fairly easy task. \n", "\n", "Since \n", "we now have the seasonal information (`season_winter`, etc), \n", "we can use the lat/lon \n", "data already in our original GaN data, the seasonal\n", "information, and the information about the solar intensity from\n", "the new dataset to make a\n", "determination on which locations would be best\n", "served to see the Northern Lights.  The binary label\n", "with just  tell us a location is a good candidate (labeled `1`),\n", "it won't tell us it is guaranteed -- and \n", "yes, our rudimentary model is lacking some additional\n", "granularity which will make it more useful and powerful.\n", "\n", "To select a random subset of the data that we know\n", "would be in the positive case requires us to pick data that are\n", "within the correct season, that are within the correct lat/lon, and\n", "that have a solar intensity that would likely produce Auroral activity. \n", "\n", "We need to split the full dataset into a subset, and use\n", "part of this subset  as a positive\n", "set and use the other part of the data as negative sets.\n", "These two sets combined will represent\n", "your _training data_. \n", "\n", "Once we have training data, we need testing data.\n", "The testing data will come from another random subsample\n", "of the original data which is labeled data.  It _must not_\n", "be data that came from or that was not used within the training set.\n", "This is a form of cheating, that we do not want to participate\n", "in when building models.\n", "\n", "**&#167; Task:**  **2.1 Split the merged data set into a random sample of 25% of the data.**\n", "\n", "Make sure the data includes at least 2500 data points \n", "which have a latitude greater than 60.\n", "\n", "The total amount of data will be between 25-35K data\n", "instances (rows).\n", "\n", "\n", "**&#167; Task:**  **2.2 Create a new column, `label` which has a `1` or `0` based on the criteria given,**\n", "\n", "Place a `1` in the `label` column when the following are\n", "satisfied:\n", "\n", "* the `Latitude` is greater than 60,\n", "* the `SQMReading` is greater than 21,\n", "* the `Ap` reading is greater than 26.\n", "\n", "Otherwise place a `0` in the column.\n", "\n", "\n", "**&#167; Task:**  **2.3 Create test and training files from the data.**\n", "\n", "Store the labeled data accordingly:\n", "\n", "* save 70% of the newly labeled data (random subset)\n", "  into a file called `train.csv` (use `to_csv()` as \n", "  you have in the past),\n", "* save the remaining 30% of the newly labeled \n", "  data into file called `test.csv`. \n", "\n", "\n", "\n", "### (25%) Build a RandomForest classifier to learn the Aurora prediction label. \n", "\n", "In this third part the fun really begins -- \n", "believe it or not, the hard part is behind us. \n", "\n", "We're going to\n", "build a binary classifier that's going to predict the outcome of whether\n", "a given unlabeled data point this is a good location for Borealis or\n", "not and of course now that we\n", "have `SQMReading` data (from our prio work) \n", "for all of the data set we can make a prediction based on\n", "that as well. \n", "\n", "Intuitively, the darker skies with  higher intensity \n", "solar activity (that\n", "are strong enough) alonside  the seasonal parameters in line\n", " with the data, _should_ allow our algorithm to learn the\n", "features that allow it to \n", "make a good prediction.  Though this is a simple\n", "classifier it will still yield important information\n", "whether or not these are good locations\n", "for seeing (or have higher potential for seeing the) Aurora Borealis. \n", "\n", "In this\n", "particular case, we know that a binary classifier might not be granular\n", "enough for a sophisticated \n", "determination, but our goal is actually just to get our feet wet in a\n", "classifier development cycle.\n", "\n", "**&#167; Task:**  **3.1 Use `sklearn.ensemble.RandomForestClassifier` to build the classifier \n", "  from your training data.**\n", "\n", "* study [sklearn.ensemble.RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html),\n", "* implement the classifier and train it on the data \n", "  in your `train.csv`\n", "\n", "\n", "You will receive further guidance on the best parameters to\n", "choose.\n", "\n", "\n", "\n", "### (25%) Complete the online assessment. \n", "\n", "Once done with the prior assignment the parts, the\n", "last part requires you to just\n", "paste your solution to the questions below.\n", "\n", "This will allow you to complete the work\n", "_offline_ then just submit it to your BB \n", "for the final points.\n", "\n", "You should also make sure to leave your\n", "solution in your submitted notebook as well --\n", "they should match up completely \n", "and this match will be verified.\n", "\n", "**&#167; Task:**  **4.1 After turning in your BB  notebook solution,  paste the  completed table \n", " into the online HW4 assessment.**\n", "\n", " You do not need to paste the code -- just the \n", " table and the classification\n", " report output.\n", "\n", " * learn to use [`sklearn.classification_report()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html),\n", " * make sure you use your test dataset in `test.csv` \n", "   for `y_true` and you will use your\n", "   model output on the test set as `y_pred`, this \n", "   will make certain you are _truly_ testing\n", "   your model on unseen data and **not** the data \n", "   that you trained on. \n", "\n", "\n", "**&#167; Task:**  **4.2 Provide some insight into your report.**\n", "\n", "In your answer (notebook and your Blackboard assessment submission)\n", "provide two sentences on how you think\n", "your classifier did.  Make a statement about whether \n", "it would be good enough to put into public/production use,\n", "say as a tool that a travel agent might use to specialize\n", "in highly effective Northern Lights tours.\n", "\n", "\n", "\n"]}], "metadata": {"anaconda-cloud": {}, "kernelspec": {"display_name": "Python [default]", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.1"}, "toc": {"colors": {"hover_highlight": "#DAA520", "navigate_num": "#000000", "navigate_text": "#333333", "running_highlight": "#FF0000", "selected_highlight": "#FFD700", "sidebar_border": "#EEEEEE", "wrapper_background": "#FFFFFF"}, "moveMenuLeft": true, "nav_menu": {"height": "12px", "width": "252px"}, "navigate_menu": true, "number_sections": false, "sideBar": true, "threshold": "1", "toc_cell": false, "toc_section_display": "block", "toc_window_display": true, "widenNotebook": false}}, "nbformat": 4, "nbformat_minor": 0}